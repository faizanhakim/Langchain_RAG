{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a515336e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import langchain\n",
    "import langsmith\n",
    "import chromadb\n",
    "import asyncio\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4def135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c34f67",
   "metadata": {},
   "source": [
    "### **Text Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6cba1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_and_clean_pdf(file_path, min_chunk_length=10):\n",
    "    \n",
    "    try:\n",
    "        raw_text = extract_text(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    text = re.sub(r'(\\w)-\\s*\\n\\s*(\\w)', r'\\1\\2', raw_text)\n",
    "\n",
    "    # 3. Split the text into potential chunks based on double newlines\n",
    "    raw_chunks = text.split('\\n\\n')\n",
    "    \n",
    "    cleaned_chunks = []\n",
    "    for chunk in raw_chunks:\n",
    "        # 4. Clean up each individual chunk\n",
    "        # Collapse single newlines and multiple spaces\n",
    "        cleaned_chunk = re.sub(r'\\s*\\n\\s*', ' ', chunk).strip()\n",
    "        cleaned_chunk = re.sub(r'\\s+', ' ', cleaned_chunk)\n",
    "\n",
    "        # 5. Filter out unwanted chunks based on generic rules\n",
    "\n",
    "        # a) Filter out short chunks that are likely headers, footers, or noise\n",
    "        if len(cleaned_chunk) < min_chunk_length:\n",
    "            continue\n",
    "\n",
    "        # b) Filter out chunks that resemble table of contents entries (e.g., \"Introduction ..... 5\")\n",
    "        if re.search(r'\\.{5,}|_{5,}', cleaned_chunk):\n",
    "            continue\n",
    "            \n",
    "        # c) Filter out chunks that are likely just page numbers or simple headers/footers\n",
    "        # This checks if a chunk has a very low ratio of alphabetic characters\n",
    "        if len(cleaned_chunk) > 0 and sum(c.isalpha() for c in cleaned_chunk) / len(cleaned_chunk) < 0.6:\n",
    "            continue\n",
    "            \n",
    "        # d) Filter out common academic/report metadata lines\n",
    "        if re.match(r'^(DOI|ISBN|ISSN):', cleaned_chunk, re.IGNORECASE):\n",
    "            continue\n",
    "\n",
    "        # If the chunk passes all filters, add it to the list\n",
    "        cleaned_chunks.append(cleaned_chunk)\n",
    "            \n",
    "    return cleaned_chunks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a601c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOAA’S 1981–2010 U.S. CLIMATE NORMALS An Overview',\n",
       " 'bY AntHonY Arguez, imke Durre, scott Applequist, russell s. Vose, micHAel F. squires, XungAng Yin, ricHArD r. Heim Jr., AnD timotHY w. owen',\n",
       " 'The latest 30-year U.S. Climate Normals, available from the National Climatic Data Center,',\n",
       " 'were calculated for over 9,800 weather stations and include several new products',\n",
       " 'and methodological enhancements.',\n",
       " 'C limate normals are typically defined as 30-yr',\n",
       " 'averages of meteorological conditions, such as air temperature, precipitation, etc. They are arguably the most fundamental attributes of the climate of a given locale. In fact, the terms normal and climatology are often used interchangeably. As a measure of central tendency, climate normals characterize the background state about which anomalous conditions and even extremes are allowed to operate. They can be used to determine what crops to plant, what clothes to pack for an extended trip, the rates a power company can charge its customers, where and when to schedule an outdoor wedding, and countless other applications.',\n",
       " 'AFFILIATIONS: Arguez, Durre, Applequist, Vose, squires, Heim, AnD owen—NOAA/National Climatic Data Center, Asheville, North Carolina; Yin*—STG, Inc., Asheville, North Carolina CORRESPONDING AUTHOR: Anthony Arguez, NOAA/NCDC, Room 506, 151 Patton Avenue, Asheville, NC 28801 *CURRENT AFFILIATION: ERT, Inc., Asheville, North Carolina E-mail: anthony.arguez@noaa.gov',\n",
       " 'The abstract for this article can be found in this issue, following the table of contents. DOI:10.1175/BAMS-D-11-00197.1',\n",
       " 'In the United States, the term normals is also commonly used in a broader sense to refer to a full suite of products issued by the National Oceanic and Atmospheric Administration (NOAA) that describes climatological conditions with 30-yr averages and other statistics (e.g., standard deviations). The new 1981–2010 set of NOAA’s climate normals are described herein and replace the 1971–2000 normals that were released in the early 2000s. The overarching goals of NOAA’s 1981–2010 U.S. Climate Normals are sixfold:',\n",
       " '• to produce high-quality climate normals for as many U.S. stations as possible, including estimates for short-record stations;',\n",
       " '• to compute the climate normals in a manner that is representative of the 1981–2010 time period, including stations with incomplete observing records;',\n",
       " '• to compute the climate normals such that they reflect the station locations and their observing practices at the end of 2010;',\n",
       " '• to add new products to meet user needs as identified via user engagement during the development process;',\n",
       " '• to develop new statistical techniques as needed to',\n",
       " 'meet the goals listed above; and',\n",
       " 'november 2012AmerICAnmeTeoroLoGICAL SoCIeTY| • to provide initial access to the new climate normals',\n",
       " 'The new normals include three major product lines, each of which was produced separately: temperature-related, precipitation-related, and hourly normals. This paper provides a general overview of the temperature-related and precipitation-related products, which contain climate statistics at the daily, monthly, seasonal, and annual time scales. The hourly normals are described by Applequist et al. (2012) in an article in this edition of BAMS. Readers interested in additional methodological details about the daily and monthly normals should consult the documentation available from the NOAA Normals website (www .ncdc.noaa.gov/oa/climate/normals/usnormals.html).',\n",
       " 'HISTORY OF NOAA’S CLIMATE NORMALS. NOAA’s National Climatic Data Center (NCDC) has a responsibility to fulfill the mandate of Congress “. . . to establish and record the climatic conditions of the United States.” This responsibility stems from a provision of the Organic Act of 1 October 1890, which established the Weather Bureau as a civilian agency (15 U.S.C. 311). Furthermore, the Federal Records Act of 1950 (Public Law 754) established NOAA’s NCDC as the official archive for weather records. In contrast with many nonofficial computations of climatological means from a myriad of sources, NCDC is the official source for calculations of U.S. normals. This official status is in keeping with NCDC’s monitoring reporting responsibilities.',\n",
       " 'The mandate to describe the climate was combined with guidelines established through international agreement. From its inception in 1950, the United Nations’ World Meteorological Organization (WMO) has recognized the need for standardizing the computation of climatological statistics and their',\n",
       " 'international exchange, promoting the worldwide use of technical standards and uniform publication of these data. The end of a decade has been set by the WMO as the desirable term for a 30-yr period from which to calculate climatic conditions (WMO 1983, 1984, 1989).',\n",
       " 'Every 30 years, climatological standard normals are computed as part of an international effort led by the WMO. Standard normals for three periods (1901– 30, 1931–60, and 1961–90) have been distributed by the WMO and its predecessor (the International Meteorological Organization) to the member nations (Heim 1997). The next WMO-mandated normals will cover the 1991–2020 period.',\n",
       " 'Starting with the 1921–50 period, NOAA (and its predecessors) computed decennial 30-yr climate normals for selected temperature and precipitation elements for a large number of U.S. climate and weather stations (Heim 1996; Owen and Whitehurst 2002). The normals from 1931 to 1960 to present are in NCDC’s archives. The 1921–50 normals, which were the first normals set prepared according to WMO standards, are available from NCDC on microfiche only. The number of stations included in NOAA’s climate normals has increased dramatically over the years (see Table 1). Currently, climate normals are computed for stations in the United States (including Alaska and Hawaii) as well as U.S. territories, commonwealths, compact of free association nations, and one Canadian station that is part of the U.S. Climate Reference Network’s comparative data exchange initiative with Environment Canada (see Fig. 1).',\n",
       " 'PRODUCTS INCLUDED IN THE 1981– 2010 CLIMATE NORMALS. NCDC released numerous climate normals products on 1 July 2011. These include station-based temperature, precipitation, snowfall, and snow depth normals at the daily, monthly, seasonal, and annual time scales. Also included a re he at i ng a nd c o ol i ng degree days; number of days per month above/below certain temperature thresholds and above certain precipitation/snowfall/snow depth thresholds; and precipitation, snowfall, and snow depth probabilities and percentiles (see Table 2). Since NOAA reports normals in imperial',\n",
       " 'Table 1. Number of temperature and precipitation stations, by normals period. This includes various estimates for short-record stations over the years.',\n",
       " 'Precipitation stations',\n",
       " 'Normals period',\n",
       " 'Temperature stations',\n",
       " 'november 2012| units (degrees Fahrenheit and inches), this convention is used in this manuscript as well. Precipitation normals are calculated for about 9,300 stations. Snowfall normals are available for about 6,400 of these stations, of which about 5,300 also have snow depth normals. Temperature-related normals were computed for about 7,500 stations. The greater number of stations with precipitation normals versus temperature normals is primarily due to the fact that around one-third of all stations in the U.S. Cooperative Observer Network do not report temperature. Accounting for precipitation-only and temperatureonly normals stations, over 9,800 stations are included in the new normals. The following subsections provide brief overviews of the temperature-related and precipitation-related normals.',\n",
       " 'Temperature-related normals. The key underlying variables used to compute all temperature-related normals are daily obser vations of ma ximum',\n",
       " 'temperature (Tmax) and minimum temperature (Tmin). As is customary, “mean temperature” (Tavg) is defined as the average of Tmax and Tmin for the day, and the diurnal temperature range (DTR) is the difference between Tmax and Tmin. Daily, monthly, seasonal, and annual normals are available for these four variables, as are standard deviations at the daily and monthly scale. Heating degree days (HDDs) and cooling degree days (CDDs) are temperature-based metrics of heating and cooling demand, respectively, derived from Tavg data. Normals of HDDs and CDDs were calculated at the daily, monthly, seasonal, and annual time scales. In addition, frequencies of threshold exceedance are included for both Tmax and Tmin at the monthly, seasonal, and annual time scales (see Table 3 for the list of temperature thresholds used). Examples include the mean number of days in July on which the daily maximum temperature reaches or exceeds 90°F and the mean number of days in winter with a daily minimum temperature of 32°F or below.',\n",
       " 'Fig. 1. Locations of the ~9,800 normals stations in (a) the continental United States and Canada, (b) the Pacific Ocean, (c) Alaska, (d) Hawaii, and (e) the Caribbean Sea.',\n",
       " 'november 2012AmerICAnmeTeoroLoGICAL SoCIeTY| Precipitation-related climate normals. Normals of precipitation, snowfall, and snow depth are all based on daily observations. Precipitation refers to rainfall plus snow water equivalent. Averages of precipitation and snowfall totals are computed at the monthly, seasonal, and annual time scales. Daily averages of precipitation and snowfall are not provided explicitly since the daily distributions of these variables tend to be strongly positively skewed with a mode of zero. Instead, month-to-date and year-to-date (January– December) precipitation and snowfall normals are provided. Frequencies of threshold exceedance are provided at the daily, monthly, seasonal, and annual time scales. All frequencies of threshold exceedance (including temperature frequencies) are scaled if necessary to account for missing values. The daily frequencies are expressed as probabilities. In fact, the daily probabilities for amounts above the lowest threshold (Table 3) are equivalent to the probability of occurrence for measurable amounts. For example, the probability of precipitation ≥ 0.01 in. represents the probability of measurable precipitation. Monthly,',\n",
       " 'seasonal, and annual frequencies are reported as average number of days above the threshold value (analogous to the temperature frequencies). In addition, the 25th, 50th, and 75th percentiles are provided in two ways. For each month of the year, they are expressed as percentiles of monthly precipitation and snowfall totals. On the daily time scale they are calculated from nonzero daily precipitation, snowfall, and snow depth values.',\n",
       " 'M ETHODOLOGICAL OVE RVIEW. The underlying values used to compute the 1981–2010 normals come from the Global Historical Climatology Network–Daily (GHCN-Daily) dataset (Menne et al. 2012). As its name suggests, this dataset contains daily observations for many atmospheric variables worldwide and is the most comprehensive set of daily climate data for the United States. The data values have undergone extensive quality assurance (QA) as described by Durre et al. (2010). A majority of the stations included in the 1981–2010 climate normals record their daily observations at',\n",
       " 'Table 2. NOAA’s 1981–2010 Climate Normals suite of products (by time scale). Check marks indicate the availability of climate normals for a particular variable and time scale. The asterisks denote that daily precipitation/snowfall normals are reported as month-to-date and year-to-date normals in lieu of explicit daily averages.',\n",
       " 'Seasonal Annual',\n",
       " 'Maximum temperature',\n",
       " 'Minimum temperature',\n",
       " 'Mean temperature',\n",
       " 'Diurnal temperature range',\n",
       " 'Heating degree days',\n",
       " 'Cooling degree days',\n",
       " 'Precipitation (liquid equivalent)',\n",
       " 'Maximum temperature',\n",
       " 'Minimum temperature',\n",
       " 'Mean temperature',\n",
       " 'Diurnal temperature range',\n",
       " 'Maximum temperature',\n",
       " 'Minimum temperature',\n",
       " 'Precipitation (liquid equivalent)',\n",
       " 'Snow depth',\n",
       " 'Precipitation (liquid equivalent)',\n",
       " 'Snow depth',\n",
       " 'Standard deviations',\n",
       " 'Frequencies of threshold exceedance',\n",
       " 'Percentiles',\n",
       " 'november 2012| or near 7 a.m. local time, with smaller percentages of stations observing in the late afternoon or around midnight. Each station is assigned the same identifier used in the GHCN-Daily dataset; corresponding metadata, such as latitude, longitude, station name, and so on, are taken directly from the GHCN-Daily station inventory. Note that the GHCN-Daily station IDs (e.g., USW00023174 for Los Angeles International Airport) are based on the National Weather Service’s (NWS’s) Cooperative Observer Program (COOP) and/or Weather Bureau–Army–Nav y (WBAN) identifiers, not the airport codes (e.g., LAX) that are commonly used for airports.',\n",
       " 'The QA checks applied to GHCN-Daily flag a portion of the daily observations as erroneous. These erroneous data values are treated as “missing values” in the computation of climate normals. Durre et al. (2010) estimate that the false positive rate is on the order of 1%–2%. However, this effect is unlikely to have any appreciable impact on the climate normals due to the nature of long-term averaging. All 1981–2010 climate normal values are accompanied by a completeness flag, which is an indication of how many nonmissing and unflagged values (i.e., “good” values) are used in the calculation. In general, a station must have at least 10 “sufficiently complete” months for each month of the year for normals to be computed (although estimated normals are computed for some shorter records as described below). The completeness criteria are loosely based on the guidelines provided by the World Meteorological Organization (WMO 1989, 2007). All reported climate normals are representative of the local observation time (of day) for the station and are rounded to a fixed precision (e.g., HDD/CDD normals are rounded to whole degrees Fahrenheit). The remainder of this section highlights the most notable methodological enhancements and additions in the 1981–2010 Climate Normals compared to previous installments of this product line.',\n",
       " 'Higher-quality monthly data. The 1971–2000 temperature normals were computed from monthly temperatures that were adjusted for inhomogeneities using the methods described by Peterson and Easterling (1994) and Easterling and Peterson (1995). Building on this previous work, the monthly temperature data (Tmax and Tmin) used to compute the 1981–2010 normals are first calculated from GHCN-Daily and subsequently undergo robust QA (Menne et al. 2009) and homogenization using the pairwise comparison technique described by Menne and Williams (2009). Further, by statistical design,',\n",
       " 'Table 3. Thresholds used in exceedance frequencies, by variable.',\n",
       " 'Thresholds',\n",
       " 'Precipitation (in.)',\n",
       " 'Snowfall (in.)',\n",
       " 'Snow depth (in.)',\n",
       " 'all temperature-related normals across all time scales (including the daily time scale) reflect the QA and homogenization applied to the monthly Tmax and Tmin data. For example, our statistical procedures ensure that the mean of the 31 daily Tmin normals in January average to the relevant monthly January Tmin normal, which in effect passes through monthly QA and adjustments down to the daily time scale. For precipitation, snowfall, and snow depth, we rely fully on the comprehensive set of QA procedures that are part of GHCN-Daily (Durre et al. 2010), since QA at the monthly time scale tends to be less effective for these variables. In addition, no effort was made either to identify or to remove inhomogeneities in the precipitation-related variables since no technique had been developed that was suitable for a station network as large and diverse as that used here.',\n",
       " 'Daily climate normals based on daily data. In the 1971–2000 climate normals, all daily normals were calculated using a cubic spline fit through the monthly normals. In other words, no daily data were explicitly utilized to refine the shape of the annual cycle. In contrast, the 1981–2010 Climate Normals make extensive use of daily observations from GHCN-Daily. This allows for a more precise representation of intraseasonal temperature signals using harmonic analysis and facilitates the inclusion of additional precipitation-related parameters such as daily percentiles, month-to-date and year-to-date normals, and daily probabilities',\n",
       " 'Direct computation of heating and cooling degree days. Previous installments of NOAA’s climate normals have computed HDD/CDD normals using a parametric method described by Thom (1954, 1966). In the 1971–2000 Climate Normals, monthly degree-day normals were calculated directly from daily data for a small fraction of the stations (first-order stations), and the daily degree-day normals for these stations were calculated as the cubic spline fit through the monthly',\n",
       " 'november 2012AmerICAnmeTeoroLoGICAL SoCIeTY| normals. A modification of the “Thom method” was used for all other stations. The 1981–2010 HDD/CDD normals were computed more directly using a 15-day windowing approach that exploits both the improved daily temperature normals and the distribution of daily observations in the window about these normals. Further, all monthly degree-day normals are calculated as the sums of the corresponding daily degree-day normals.',\n",
       " 'Quasi normals for short-record stations. For active short-record stations that fail the 10-yr completeness criterion described above but do have at least two years of sufficiently complete months for each month of the year, so-called “quasi normals,” or estimated normals, are provided. Included in the active short-record stations are not only NWS sites',\n",
       " 'but also stations in the U.S. Climate Reference Network, a national network operational since 2001 that was designed explicitly to measure long-term (e.g., 50–100 years or longer) climate variability and change. Average monthly temperature and precipitation normals are estimated using linear combinations of the normals from neighboring longer-record stations closely following the “pseudonormals” methodology outlined by Sun and Peterson (2005, 2006). Other statistics that are in some way dependent on these average monthly values are also available for the short-record stations. Quasi normals are computed for all temperature-related variables except standard deviations as well as for month-to-date, year-to-date, monthly, seasonal, and annual precipitation averages. Quasi normals are not provided for snowfall or snow depth parameters.',\n",
       " 'Table 4. Monthly and annual normals of Tmax (°F), Tmin (°F), precipitation (in.), and snowfall (in.) for select U.S. cities. In the column headings, “Var” stands for variable, the single letters represent the 12 months from January through December, and “Ann” stands for annual. The expression “Prcp” refers to liquid-equivalent precipitation. For display purposes, trace amounts of average precipitation and snowfall totals are rounded to zero.',\n",
       " 'New York, NY LaGuardia AP',\n",
       " 'Los Angeles, CA Intl AP',\n",
       " 'Washington, DC',\n",
       " 'Natl Arboretum',\n",
       " 'Houston, TX',\n",
       " 'Bush Intl AP',\n",
       " 'Boulder, CO',\n",
       " 'Fairbanks, AK',\n",
       " 'november 2012| RESULTS. NOAA’s 1981–2010 Climate Normals, like previous installments, showcase the broad array of climatological regimes present across the United States, not only within the conterminous United States but also across the full array of station locations shown in Fig. 1. Table 4 shows the monthly and annual normals of Tmax, Tmin, precipitation (prcp), and snowfall for 12 stations across the United States, including stations in Alaska and Hawaii. The January Tmin normal is –6.6°F in International Falls, Minnesota, and –16.9°F in Fairbanks, Alaska, whereas the January Tmin normals in Miami, Florida, and Honolulu, Hawaii, are 59.9°F and 66.3°F, respectively. July Tmax normals vary to a lesser degree across the United States, with values of 72.7°F in Fairbanks, 73.8°F in Los Angeles, California, 81.6°F in State College, Pennsylvania, and 93.7°F in Houston, Texas. Annual precipitation normals across the United States vary from less than 5 in. to well over 200 in. at some Pacific island stations. Los Angeles, Fairbanks, Honolulu, and Spokane, Washington, each',\n",
       " 'receive less than 20 in. of precipitation per year on average, whereas the annual precipitation normal is nearly 45, 50, and 62 in. in New York, Houston, and Miami, respectively. Annual snowfall normals vary from zero in much of the southern tier of the United States to well over 200 in. in some areas. It is not uncommon for relatively dry stations such as Boulder and Fairbanks to have annual snowfall normals in excess of 50 in.',\n",
       " 'Figure 2 shows the spatial patterns of Tavg and precipitation normals over the conterminous United States. Annual Tavg normals follow a generally north–south pattern due to latitudinal variations in solar radiation (Fig. 2a), with some deviation primarily in the western part of the country in highland regions. The warmest Tavg normals are found in Florida and the desert Southwest, whereas the coldest normals are present in parts of the Rockies and near the Canadian border. Annual precipitation displays a typical east–west gradient with drier conditions in the West and substantially wetter conditions in the',\n",
       " 'Table 4. Continued.',\n",
       " 'State College, PA',\n",
       " 'Spokane, WA Intl AP',\n",
       " 'St. Louis, MO',\n",
       " 'Lambert AP',\n",
       " 'Honolulu, HI',\n",
       " 'International Falls, MN AP',\n",
       " 'november 2012AmerICAnmeTeoroLoGICAL SoCIeTY| Fig. 2. (a) Annual Tavg (°F) normals for 1981–2010. (b) Annual precipitation (in.) normals for 1981–2010. (c) Difference between the new Tavg normals for the 1981–2010 period and comparable averages for the 1971–2000 period. (d) Percent difference between the new precipitation normals for 1981–2010 and comparable averages for the 1971–2000 period. Only stations with at least 25 years of complete monthly data in both time periods are plotted.',\n",
       " 'Table 5. Monthly and annual normals for Chicago Midway AP 3 SW. Abbreviations are as in Table 4. For display purposes, average numbers of days less than 0.5 are rounded to zero. Precipitation and snowfall percentiles refer to percentiles of monthly totals.',\n",
       " 'Precipitation',\n",
       " 'Days on which Tmax ≥ 90°F',\n",
       " 'Days on which Tmax ≥ 70°F',\n",
       " 'Days on which Tmax ≥ 50°F',\n",
       " 'november 2012| East, with the notable exception of very wet conditions in the maritime climate zones along the West Coast (Fig. 2b). The driest stations are concentrated in the Southwest and Intermountain West, while the wettest stations are along the central Gulf Coast and in areas associated with orographically enhanced precipitation such as the Pacific Northwest and Mount Washington, New Hampshire.',\n",
       " 'To illustrate the breadth and utility of the products in NOAA’s 1981–2010 U.S. Climate Normals, Table 5',\n",
       " 'shows a multitude of monthly and annual normals for Chicago Midway AP 3 SW. Annual normals of HDD and CDD (base 65°F) are 5,989 and 1,045, respectively, suggesting almost 6 times more weather-based demand (not accounting for fuel mix and other factors) for heating in colder months than for cooling in warmer months. Tmax reaches or exceeds 90°F, an average of 15.1 days per year, with 6.3 days on average in July alone. Individuals considering a move to Chicago can expect over 80% of winter nights to dip below freezing,',\n",
       " 'Table 5. Continued.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/bams-d-11-00197.1.pdf'\n",
    "pdf_text = extract_and_clean_pdf(data_path)\n",
    "pdf_text[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dda38cf",
   "metadata": {},
   "source": [
    "### **Text Chunking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba14a739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "chunks = splitter.split_text(''.join(pdf_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf23c0",
   "metadata": {},
   "source": [
    "### **Text Embeddings and Vector Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af448b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08516b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3a9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client() # Can be swapped for PersistentClient\n",
    "collection = chroma_client.create_collection(name='weather_client_nomral_documents', embedding_function=embedding_function, get_or_create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d93908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [str(uuid.uuid4()) for _ in chunks]\n",
    "meta_data = [{\"chunk_number\": chunk_num} for chunk_num in range(len(chunks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ad2744",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    ids=ids,\n",
    "    documents=chunks,\n",
    "    metadatas=meta_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a3ea0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['f32ddfba-fd47-4bf2-9bf1-dcc2f366762f'],\n",
       " 'embeddings': array([[ 2.82622036e-02, -9.28624626e-03,  2.75775138e-02,\n",
       "          4.58638035e-02, -4.98209745e-02, -3.60961109e-02,\n",
       "          2.74599902e-02,  6.24627545e-02,  5.37991486e-02,\n",
       "          9.98964906e-03,  8.62965733e-03, -9.26789343e-02,\n",
       "          7.17553273e-02, -1.05711410e-03,  4.25285026e-02,\n",
       "         -5.01970015e-03, -3.89464274e-02, -8.42363164e-02,\n",
       "         -1.97020788e-02, -8.06714781e-03,  3.45610976e-02,\n",
       "         -1.30837539e-03, -3.54627110e-02, -2.21950337e-02,\n",
       "          2.74343248e-02, -7.26808980e-02, -3.30300406e-02,\n",
       "          2.76967995e-02,  1.72279514e-02,  1.35249227e-01,\n",
       "         -6.68658316e-02,  6.30032867e-02,  1.52196690e-01,\n",
       "         -3.71630155e-02, -7.25311739e-03, -9.40596014e-02,\n",
       "         -6.03209771e-02,  5.67723066e-03,  4.58433386e-03,\n",
       "          2.50840709e-02,  1.76992044e-02, -1.16799772e-02,\n",
       "          6.12996519e-02,  2.31932774e-02, -5.40035926e-02,\n",
       "          2.62212902e-02, -6.26031980e-02,  4.10126708e-03,\n",
       "         -1.01887755e-01,  6.14676252e-02,  2.46333946e-02,\n",
       "          1.00983523e-01, -6.54246062e-02,  5.51602766e-02,\n",
       "         -1.21838739e-02, -2.52964664e-02,  8.64312891e-03,\n",
       "         -1.02150559e-01,  2.56326445e-03, -3.97358388e-02,\n",
       "         -2.74934992e-02, -9.65564512e-03, -7.98611641e-02,\n",
       "          3.77704427e-02,  1.17361337e-01,  1.30670390e-03,\n",
       "         -3.60219483e-03,  6.70694038e-02,  2.12245733e-02,\n",
       "          1.24930209e-02, -5.01449518e-02,  3.28583159e-02,\n",
       "         -3.63259725e-02,  7.27963597e-02,  2.63407994e-02,\n",
       "         -5.93167059e-02, -5.33329695e-02,  1.78484209e-02,\n",
       "         -3.16373371e-02,  1.52332298e-02, -1.35971755e-02,\n",
       "          3.36701125e-02,  9.85623747e-02, -7.36777857e-02,\n",
       "          3.54778357e-02,  4.24831994e-02,  7.74095878e-02,\n",
       "          6.64132237e-02,  8.20667297e-03,  1.68077461e-02,\n",
       "         -6.74553886e-02, -5.52431419e-02, -9.33869183e-03,\n",
       "          6.33182973e-02, -1.00415081e-01,  8.75614285e-02,\n",
       "          4.26963605e-02, -7.51557201e-02,  8.53110626e-02,\n",
       "          1.21559231e-02,  7.45576108e-03, -1.23731002e-01,\n",
       "          3.32120769e-02, -2.71003097e-02, -3.56307663e-02,\n",
       "         -8.68408307e-02, -5.60895260e-03, -1.50797619e-02,\n",
       "         -6.27599135e-02, -2.83926353e-02, -2.77728867e-02,\n",
       "         -1.42327901e-02,  6.28203601e-02, -8.64916388e-03,\n",
       "          8.40889663e-03,  7.58298486e-03, -6.49172068e-02,\n",
       "          7.64570683e-02,  2.94727441e-02, -3.05478945e-02,\n",
       "         -7.84335136e-02,  3.34791727e-02, -2.42481958e-02,\n",
       "         -4.75634821e-02,  2.37079822e-02,  5.26309274e-02,\n",
       "          4.34357487e-02, -2.42568531e-33,  7.04884604e-02,\n",
       "         -1.32968634e-01, -5.20959906e-02, -2.97036935e-02,\n",
       "          7.42907971e-02, -1.55444052e-02, -4.71043698e-02,\n",
       "         -4.86014672e-02,  9.04287100e-02, -1.65653080e-02,\n",
       "          3.04099005e-02,  4.00080197e-02,  5.51563650e-02,\n",
       "          7.87327252e-03,  1.22607322e-02,  4.58461791e-03,\n",
       "         -3.55667109e-03,  5.54394647e-02, -1.90748144e-02,\n",
       "         -3.17289196e-02, -1.18491188e-01, -6.69924840e-02,\n",
       "          2.06178501e-02,  6.48757592e-02,  7.49657303e-02,\n",
       "          5.03879189e-02,  1.89508963e-02, -2.50151125e-03,\n",
       "          1.25007490e-02,  4.28264681e-03,  1.07095279e-01,\n",
       "          6.71714842e-02,  1.45451725e-02, -1.14080213e-01,\n",
       "          6.07422888e-02, -4.38656174e-02,  4.11157422e-02,\n",
       "          6.31750748e-02,  4.37995885e-03,  2.38314383e-02,\n",
       "         -2.10592933e-02, -6.34737164e-02, -2.18267515e-02,\n",
       "         -2.18255538e-02,  5.81584163e-02, -2.32041981e-02,\n",
       "          7.05614835e-02,  6.14707591e-04, -1.92981008e-02,\n",
       "         -4.27318960e-02, -4.70367447e-02, -1.71289556e-02,\n",
       "          1.41726574e-02, -1.06376689e-02,  1.59581210e-02,\n",
       "          1.04069844e-01,  6.54778928e-02,  1.14696566e-02,\n",
       "         -4.19859029e-02,  1.92065891e-02, -4.13570590e-02,\n",
       "          2.73764729e-02,  9.45668519e-02, -6.79414421e-02,\n",
       "          7.56728053e-02,  5.86196817e-02, -8.23306516e-02,\n",
       "          4.21514325e-02,  4.66479734e-02,  6.70057163e-02,\n",
       "          6.04584999e-02,  4.08706218e-02, -1.46628702e-02,\n",
       "         -2.71811392e-02, -1.92828011e-02,  3.11842635e-02,\n",
       "          7.59316459e-02, -2.10422594e-02, -3.03672943e-02,\n",
       "          7.12000877e-02, -4.88293916e-02,  2.79502221e-03,\n",
       "         -6.83542043e-02, -4.20665666e-02, -7.06036165e-02,\n",
       "          2.53696200e-02,  5.84710799e-02,  2.08982173e-02,\n",
       "         -1.17142787e-02, -4.47278023e-02,  4.35454883e-02,\n",
       "         -4.13853750e-02,  1.18072587e-03,  2.81359535e-02,\n",
       "         -8.56836699e-03, -7.63031612e-34, -3.27878110e-02,\n",
       "          1.17413327e-01,  4.15343046e-03,  4.51776758e-02,\n",
       "         -2.43204553e-02, -1.33933537e-02,  2.04261485e-02,\n",
       "          4.65054214e-02,  4.18108031e-02,  7.12355366e-03,\n",
       "         -8.09869904e-04,  6.35580868e-02, -1.63454209e-02,\n",
       "         -5.97509295e-02, -5.66716865e-02, -3.85341682e-02,\n",
       "         -2.95683052e-02,  6.41615363e-03, -6.79816082e-02,\n",
       "         -1.96967907e-02, -6.38647843e-03, -5.84672950e-02,\n",
       "         -4.63699512e-02, -2.18621548e-02, -7.86566641e-04,\n",
       "         -1.08209103e-02,  2.21749973e-02, -4.15573120e-02,\n",
       "         -2.74263378e-02, -5.46940640e-02, -4.40302677e-02,\n",
       "         -3.61835361e-02,  3.35424170e-02, -2.17303820e-03,\n",
       "         -1.16141122e-02, -5.70910461e-02,  1.05903275e-01,\n",
       "         -7.76376724e-02, -6.52652085e-02, -4.74718772e-02,\n",
       "         -1.20227709e-02, -2.21407264e-02,  7.73315430e-02,\n",
       "         -6.80455789e-02, -1.04383631e-02, -2.59384653e-03,\n",
       "         -8.53453297e-03,  5.64616360e-03,  5.44883236e-02,\n",
       "         -8.49168673e-02,  4.26707696e-03, -1.70999691e-02,\n",
       "         -6.34938106e-02,  9.83793437e-02,  1.63021032e-02,\n",
       "          3.00606098e-02, -6.68716282e-02, -4.03601415e-02,\n",
       "          3.98869580e-03,  9.55709368e-02, -3.12091261e-02,\n",
       "         -4.93147112e-02,  2.61430368e-02,  7.93099869e-03,\n",
       "         -6.23688549e-02, -4.25710641e-02, -7.82135427e-02,\n",
       "         -3.07775196e-02,  2.40289960e-02,  5.16073816e-02,\n",
       "          1.67029537e-02,  2.25071218e-02,  3.30634601e-02,\n",
       "         -9.33572873e-02, -3.34383845e-02, -2.82619894e-02,\n",
       "          1.81193892e-02,  4.57175002e-02, -3.11424602e-02,\n",
       "         -2.67818402e-02, -1.08196475e-01, -4.24482934e-02,\n",
       "         -6.84635267e-02,  5.48682958e-02, -8.19485858e-02,\n",
       "         -8.72730315e-02,  1.57925226e-02, -1.43306851e-01,\n",
       "         -7.62977591e-03,  1.94440503e-02, -1.33817559e-02,\n",
       "          5.00531197e-02, -9.78536382e-02,  5.86378798e-02,\n",
       "         -3.70597579e-02, -3.80059078e-08,  5.87829202e-02,\n",
       "         -1.82000604e-02,  1.06043052e-02, -7.96143562e-02,\n",
       "          1.17587082e-01,  1.05156034e-01,  1.71267595e-02,\n",
       "         -6.69709444e-02,  1.00587048e-02, -3.06486269e-03,\n",
       "          5.89322858e-02, -2.07734182e-02, -5.92160113e-02,\n",
       "         -2.78582610e-02,  3.70762013e-02, -2.10062433e-02,\n",
       "         -2.38167122e-03,  6.83005303e-02, -1.12142256e-02,\n",
       "         -5.89050576e-02,  1.69692580e-02, -6.32424653e-02,\n",
       "         -9.75515170e-04, -2.77723209e-03,  2.36363593e-03,\n",
       "          6.67144880e-02,  3.70219313e-02,  7.34106749e-02,\n",
       "         -1.76203512e-02,  2.89708767e-02, -4.00568247e-02,\n",
       "          8.81345652e-04,  6.57383800e-02, -7.90662691e-02,\n",
       "          1.88084524e-02,  7.53935799e-02, -2.01969407e-02,\n",
       "         -4.79001999e-02, -1.93821639e-02, -1.13453455e-02,\n",
       "          7.51442313e-02, -5.70912436e-02, -1.49635458e-02,\n",
       "          2.43676379e-02,  4.61410843e-02,  1.96612515e-02,\n",
       "          1.02643892e-02,  8.94284844e-02,  3.73763554e-02,\n",
       "          7.04934401e-03, -1.60736889e-02, -3.17875016e-03,\n",
       "          1.09656388e-02,  1.84176322e-02, -4.49711010e-02,\n",
       "          8.85395482e-02,  3.15258726e-02, -7.58880749e-02,\n",
       "         -5.69715649e-02, -2.95082647e-02,  1.78080853e-02,\n",
       "          1.59803294e-02, -3.88447344e-02, -6.03257194e-02]]),\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'included': ['embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get(random.choice(ids), include=['embeddings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f535e",
   "metadata": {},
   "source": [
    "### **Query Refinement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03bc7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39511bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_clean_output(text: str) -> list[str]:\n",
    "    cleaned_text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "    questions = [q.strip() for q in cleaned_text.split(\"\\n\") if q.strip()]\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e53babd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "different versions of the given user question to retrieve relevant documents from a vector\n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search.\n",
    "Provide these alternative questions separated by newlines.\n",
    "\n",
    "Original question: {question}\"\"\"\n",
    "\n",
    "prompt_perspectives = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9178c062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. What is the projected rate of coral reef decline at a global warming level of 1.5°C?', '2. How much of the global coral reef population is expected to decline with a global warming increase to 1.5°C?', '3. What is the anticipated coral reef loss percentage due to a global warming rise to 1.5°C?', '4. To what extent will coral reefs decline under a global warming scenario of 1.5°C?', '5. What is the expected percentage of coral reef degradation at a global warming level of 1.5°C?']\n"
     ]
    }
   ],
   "source": [
    "HUGGING_FACE_API_TOKEN = os.getenv(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "\n",
    "llm_endpoint = HuggingFaceEndpoint(\n",
    "    repo_id=MODEL_ID,\n",
    "    huggingfacehub_api_token=HUGGING_FACE_API_TOKEN,\n",
    "    task=\"conversational\" \n",
    ")\n",
    "\n",
    "# 3. Define the LLM using the modern Hugging Face Endpoint\n",
    "chat_model = ChatHuggingFace(llm=llm_endpoint)\n",
    "\n",
    "# 4. Create the query-generation pipeline using LCEL (LangChain Expression Language)\n",
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | chat_model\n",
    "    | StrOutputParser()\n",
    "    | RunnableLambda(parse_and_clean_output)\n",
    ")\n",
    "\n",
    "# 5. Invoke the pipeline\n",
    "question = \"What percentage of coral reefs are projected to decline at a global warming level of 1.5°C?\"\n",
    "response = generate_queries.invoke({\"question\": question})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14bb5",
   "metadata": {},
   "source": [
    "### **Document Retrival**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5426af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_classic.retrievers import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdd0ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "954ef923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain retriever created.\n"
     ]
    }
   ],
   "source": [
    "langchain_chroma_store = Chroma(\n",
    "    client=chroma_client,\n",
    "    collection_name=\"weather_client_nomral_documents\",\n",
    "    embedding_function=langchain_embedding_function\n",
    ")\n",
    "\n",
    "base_retriever = langchain_chroma_store.as_retriever()\n",
    "print(\"LangChain retriever created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a8e92e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "402 Client Error: Payment Required for url: https://router.huggingface.co/together/v1/chat/completions (Request ID: Root=1-68f66c0b-629b56dc19aeeaa34ea4cf4e;b32b330c-c15d-4393-b194-ce698d674ab7)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:407\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 402 Client Error: Payment Required for url: https://router.huggingface.co/together/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m retriever = MultiQueryRetriever(\n\u001b[32m      2\u001b[39m     retriever=base_retriever,\n\u001b[32m      3\u001b[39m     llm_chain=generate_queries\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mWhat percentage of coral reefs are projected to decline at a global warming level of 1.5°C?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response_docs = \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Pass as dict for the prompt\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Retrieved Documents ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(response_docs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\retrievers.py:212\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m kwargs_ = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **kwargs_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_classic\\retrievers\\multi_query.py:179\u001b[39m, in \u001b[36mMultiQueryRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_relevant_documents\u001b[39m(\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    166\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    167\u001b[39m     *,\n\u001b[32m    168\u001b[39m     run_manager: CallbackManagerForRetrieverRun,\n\u001b[32m    169\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m    170\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get relevant documents given a user query.\u001b[39;00m\n\u001b[32m    171\u001b[39m \n\u001b[32m    172\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m \u001b[33;03m        Unique union of relevant documents from all generated queries\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     queries = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.include_original:\n\u001b[32m    181\u001b[39m         queries.append(query)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_classic\\retrievers\\multi_query.py:199\u001b[39m, in \u001b[36mMultiQueryRetriever.generate_queries\u001b[39m\u001b[34m(self, question, run_manager)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_queries\u001b[39m(\n\u001b[32m    186\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    187\u001b[39m     question: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    188\u001b[39m     run_manager: CallbackManagerForRetrieverRun,\n\u001b[32m    189\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    190\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate queries based upon user input.\u001b[39;00m\n\u001b[32m    191\u001b[39m \n\u001b[32m    192\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m \u001b[33;03m        List of LLM generated queries that are similar to the user input\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m     lines = response[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_chain, LLMChain) \u001b[38;5;28;01melse\u001b[39;00m response\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3093\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3092\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3093\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3095\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m    374\u001b[39m     config = ensure_config(config)\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m    378\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1088\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     **kwargs: Any,\n\u001b[32m   1086\u001b[39m ) -> LLMResult:\n\u001b[32m   1087\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:903\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    902\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    911\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1192\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_huggingface\\chat_models\\huggingface.py:584\u001b[39m, in \u001b[36mChatHuggingFace._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[39m\n\u001b[32m    577\u001b[39m     message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    578\u001b[39m     params = {\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    580\u001b[39m         **params,\n\u001b[32m    581\u001b[39m         **({\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m    582\u001b[39m         **kwargs,\n\u001b[32m    583\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m     answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(answer)\n\u001b[32m    586\u001b[39m llm_input = \u001b[38;5;28mself\u001b[39m._to_chat_prompt(messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:919\u001b[39m, in \u001b[36mInferenceClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[39m\n\u001b[32m    891\u001b[39m parameters = {\n\u001b[32m    892\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: payload_model,\n\u001b[32m    893\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m     **(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    911\u001b[39m }\n\u001b[32m    912\u001b[39m request_parameters = provider_helper.prepare_request(\n\u001b[32m    913\u001b[39m     inputs=messages,\n\u001b[32m    914\u001b[39m     parameters=parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    917\u001b[39m     api_key=\u001b[38;5;28mself\u001b[39m.token,\n\u001b[32m    918\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    922\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:275\u001b[39m, in \u001b[36mInferenceClient._inner_post\u001b[39m\u001b[34m(self, request_parameters, stream)\u001b[39m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.iter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response.content\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:480\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: 402 Client Error: Payment Required for url: https://router.huggingface.co/together/v1/chat/completions (Request ID: Root=1-68f66c0b-629b56dc19aeeaa34ea4cf4e;b32b330c-c15d-4393-b194-ce698d674ab7)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits."
     ]
    }
   ],
   "source": [
    "retriever = MultiQueryRetriever(\n",
    "    retriever=base_retriever,\n",
    "    llm_chain=generate_queries\n",
    ")\n",
    "\n",
    "question = \"What percentage of coral reefs are projected to decline at a global warming level of 1.5°C?\"\n",
    "response_docs = retriever.invoke({\"question\": question}) # Pass as dict for the prompt\n",
    "\n",
    "print(\"\\n--- Retrieved Documents ---\")\n",
    "print(response_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc150f64",
   "metadata": {},
   "source": [
    "### **Ranking of Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2b807",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "402 Client Error: Payment Required for url: https://router.huggingface.co/together/v1/chat/completions (Request ID: Root=1-68f66c0f-0cae78031de2a7bb7d27a5f5;441b6543-6436-4df2-a21e-97d58373afff)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:407\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 402 Client Error: Payment Required for url: https://router.huggingface.co/together/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m reranked_results\n\u001b[32m     20\u001b[39m retrieval_chain = generate_queries | retriever.map() | rank_documents\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m docs = \u001b[43mretrieval_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3093\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3092\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3093\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3095\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5174\u001b[39m, in \u001b[36mRunnableEachBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5170\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5172\u001b[39m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mlist\u001b[39m[Input], config: RunnableConfig | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any\n\u001b[32m   5173\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m5174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2021\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2017\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2018\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2019\u001b[39m         output = cast(\n\u001b[32m   2020\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2021\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2022\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2023\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2024\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2029\u001b[39m         )\n\u001b[32m   2030\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2031\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5168\u001b[39m, in \u001b[36mRunnableEachBase._invoke\u001b[39m\u001b[34m(self, inputs, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   5158\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke\u001b[39m(\n\u001b[32m   5159\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5160\u001b[39m     inputs: \u001b[38;5;28mlist\u001b[39m[Input],\n\u001b[32m   (...)\u001b[39m\u001b[32m   5163\u001b[39m     **kwargs: Any,\n\u001b[32m   5164\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Output]:\n\u001b[32m   5165\u001b[39m     configs = [\n\u001b[32m   5166\u001b[39m         patch_config(config, callbacks=run_manager.get_child()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[32m   5167\u001b[39m     ]\n\u001b[32m-> \u001b[39m\u001b[32m5168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:898\u001b[39m, in \u001b[36mRunnable.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m    895\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mlist[Output]\u001b[39m\u001b[33m\"\u001b[39m, [invoke(inputs[\u001b[32m0\u001b[39m], configs[\u001b[32m0\u001b[39m])])\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(configs[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mlist[Output]\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\config.py:546\u001b[39m, in \u001b[36mContextThreadPoolExecutor.map.<locals>._wrapped_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_fn\u001b[39m(*args: Any) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontexts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:891\u001b[39m, in \u001b[36mRunnable.batch.<locals>.invoke\u001b[39m\u001b[34m(input_, config)\u001b[39m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m e\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\retrievers.py:212\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m kwargs_ = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **kwargs_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_classic\\retrievers\\multi_query.py:179\u001b[39m, in \u001b[36mMultiQueryRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_relevant_documents\u001b[39m(\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    166\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    167\u001b[39m     *,\n\u001b[32m    168\u001b[39m     run_manager: CallbackManagerForRetrieverRun,\n\u001b[32m    169\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m    170\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get relevant documents given a user query.\u001b[39;00m\n\u001b[32m    171\u001b[39m \n\u001b[32m    172\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m \u001b[33;03m        Unique union of relevant documents from all generated queries\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     queries = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.include_original:\n\u001b[32m    181\u001b[39m         queries.append(query)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_classic\\retrievers\\multi_query.py:199\u001b[39m, in \u001b[36mMultiQueryRetriever.generate_queries\u001b[39m\u001b[34m(self, question, run_manager)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_queries\u001b[39m(\n\u001b[32m    186\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    187\u001b[39m     question: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    188\u001b[39m     run_manager: CallbackManagerForRetrieverRun,\n\u001b[32m    189\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    190\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate queries based upon user input.\u001b[39;00m\n\u001b[32m    191\u001b[39m \n\u001b[32m    192\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m \u001b[33;03m        List of LLM generated queries that are similar to the user input\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m     lines = response[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_chain, LLMChain) \u001b[38;5;28;01melse\u001b[39;00m response\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3093\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3092\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3093\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3095\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m    374\u001b[39m     config = ensure_config(config)\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m    378\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1088\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     **kwargs: Any,\n\u001b[32m   1086\u001b[39m ) -> LLMResult:\n\u001b[32m   1087\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:903\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    902\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    911\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1192\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_huggingface\\chat_models\\huggingface.py:584\u001b[39m, in \u001b[36mChatHuggingFace._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[39m\n\u001b[32m    577\u001b[39m     message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    578\u001b[39m     params = {\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    580\u001b[39m         **params,\n\u001b[32m    581\u001b[39m         **({\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m    582\u001b[39m         **kwargs,\n\u001b[32m    583\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m     answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(answer)\n\u001b[32m    586\u001b[39m llm_input = \u001b[38;5;28mself\u001b[39m._to_chat_prompt(messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:919\u001b[39m, in \u001b[36mInferenceClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[39m\n\u001b[32m    891\u001b[39m parameters = {\n\u001b[32m    892\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: payload_model,\n\u001b[32m    893\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m     **(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    911\u001b[39m }\n\u001b[32m    912\u001b[39m request_parameters = provider_helper.prepare_request(\n\u001b[32m    913\u001b[39m     inputs=messages,\n\u001b[32m    914\u001b[39m     parameters=parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    917\u001b[39m     api_key=\u001b[38;5;28mself\u001b[39m.token,\n\u001b[32m    918\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    922\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:275\u001b[39m, in \u001b[36mInferenceClient._inner_post\u001b[39m\u001b[34m(self, request_parameters, stream)\u001b[39m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.iter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response.content\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:480\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: 402 Client Error: Payment Required for url: https://router.huggingface.co/together/v1/chat/completions (Request ID: Root=1-68f66c0f-0cae78031de2a7bb7d27a5f5;441b6543-6436-4df2-a21e-97d58373afff)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_classic.load import dumps, loads\n",
    "\n",
    "def rank_documents(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain = generate_queries | retriever.map() | rank_documents\n",
    "docs = retrieval_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd153e",
   "metadata": {},
   "source": [
    "### **LLM Query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0da67b",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "402 Client Error: Payment Required for url: https://router.huggingface.co/novita/v3/openai/chat/completions (Request ID: Root=1-68f6677c-40a610cf1707f9d25fe750f5;f19f4136-70cb-4880-9b78-c0b394d3f9c2)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:407\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 402 Client Error: Payment Required for url: https://router.huggingface.co/novita/v3/openai/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Pass context and question into prompt, then pass prompt to LLM\u001b[39;00m\n\u001b[32m     15\u001b[39m final_rag_chain = (\n\u001b[32m     16\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: retrieval_chain, \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: RunnablePassthrough()}\n\u001b[32m     17\u001b[39m     | prompt\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     | RunnableLambda(parse_and_clean_output)\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mfinal_rag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3091\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3089\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3090\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3091\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3092\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3093\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3812\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3806\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3807\u001b[39m         futures = [\n\u001b[32m   3808\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3809\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3810\u001b[39m         ]\n\u001b[32m   3811\u001b[39m         output = {\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m             key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   3814\u001b[39m         }\n\u001b[32m   3815\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3816\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3795\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input_, config, key)\u001b[39m\n\u001b[32m   3789\u001b[39m child_config = patch_config(\n\u001b[32m   3790\u001b[39m     config,\n\u001b[32m   3791\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3792\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3793\u001b[39m )\n\u001b[32m   3794\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3795\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3797\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3798\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3093\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3092\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3093\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3095\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5174\u001b[39m, in \u001b[36mRunnableEachBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5170\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5172\u001b[39m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mlist\u001b[39m[Input], config: RunnableConfig | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any\n\u001b[32m   5173\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m5174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2021\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2017\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2018\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2019\u001b[39m         output = cast(\n\u001b[32m   2020\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2021\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2022\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2023\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2024\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2029\u001b[39m         )\n\u001b[32m   2030\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2031\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5168\u001b[39m, in \u001b[36mRunnableEachBase._invoke\u001b[39m\u001b[34m(self, inputs, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   5158\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke\u001b[39m(\n\u001b[32m   5159\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5160\u001b[39m     inputs: \u001b[38;5;28mlist\u001b[39m[Input],\n\u001b[32m   (...)\u001b[39m\u001b[32m   5163\u001b[39m     **kwargs: Any,\n\u001b[32m   5164\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Output]:\n\u001b[32m   5165\u001b[39m     configs = [\n\u001b[32m   5166\u001b[39m         patch_config(config, callbacks=run_manager.get_child()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[32m   5167\u001b[39m     ]\n\u001b[32m-> \u001b[39m\u001b[32m5168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:898\u001b[39m, in \u001b[36mRunnable.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m    895\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mlist[Output]\u001b[39m\u001b[33m\"\u001b[39m, [invoke(inputs[\u001b[32m0\u001b[39m], configs[\u001b[32m0\u001b[39m])])\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(configs[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mlist[Output]\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\config.py:546\u001b[39m, in \u001b[36mContextThreadPoolExecutor.map.<locals>._wrapped_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_fn\u001b[39m(*args: Any) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontexts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:891\u001b[39m, in \u001b[36mRunnable.batch.<locals>.invoke\u001b[39m\u001b[34m(input_, config)\u001b[39m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m e\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\retrievers.py:212\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m kwargs_ = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **kwargs_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_classic\\retrievers\\multi_query.py:179\u001b[39m, in \u001b[36mMultiQueryRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_relevant_documents\u001b[39m(\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    166\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    167\u001b[39m     *,\n\u001b[32m    168\u001b[39m     run_manager: CallbackManagerForRetrieverRun,\n\u001b[32m    169\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m    170\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get relevant documents given a user query.\u001b[39;00m\n\u001b[32m    171\u001b[39m \n\u001b[32m    172\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m \u001b[33;03m        Unique union of relevant documents from all generated queries\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     queries = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.include_original:\n\u001b[32m    181\u001b[39m         queries.append(query)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_classic\\retrievers\\multi_query.py:199\u001b[39m, in \u001b[36mMultiQueryRetriever.generate_queries\u001b[39m\u001b[34m(self, question, run_manager)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_queries\u001b[39m(\n\u001b[32m    186\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    187\u001b[39m     question: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    188\u001b[39m     run_manager: CallbackManagerForRetrieverRun,\n\u001b[32m    189\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    190\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate queries based upon user input.\u001b[39;00m\n\u001b[32m    191\u001b[39m \n\u001b[32m    192\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m \u001b[33;03m        List of LLM generated queries that are similar to the user input\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m     lines = response[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_chain, LLMChain) \u001b[38;5;28;01melse\u001b[39;00m response\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3093\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3092\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3093\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3095\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m    374\u001b[39m     config = ensure_config(config)\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m    378\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1088\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     **kwargs: Any,\n\u001b[32m   1086\u001b[39m ) -> LLMResult:\n\u001b[32m   1087\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:903\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    902\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    911\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1192\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langchain_huggingface\\chat_models\\huggingface.py:584\u001b[39m, in \u001b[36mChatHuggingFace._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[39m\n\u001b[32m    577\u001b[39m     message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    578\u001b[39m     params = {\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    580\u001b[39m         **params,\n\u001b[32m    581\u001b[39m         **({\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m    582\u001b[39m         **kwargs,\n\u001b[32m    583\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m     answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(answer)\n\u001b[32m    586\u001b[39m llm_input = \u001b[38;5;28mself\u001b[39m._to_chat_prompt(messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:919\u001b[39m, in \u001b[36mInferenceClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[39m\n\u001b[32m    891\u001b[39m parameters = {\n\u001b[32m    892\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: payload_model,\n\u001b[32m    893\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m     **(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    911\u001b[39m }\n\u001b[32m    912\u001b[39m request_parameters = provider_helper.prepare_request(\n\u001b[32m    913\u001b[39m     inputs=messages,\n\u001b[32m    914\u001b[39m     parameters=parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    917\u001b[39m     api_key=\u001b[38;5;28mself\u001b[39m.token,\n\u001b[32m    918\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    922\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:275\u001b[39m, in \u001b[36mInferenceClient._inner_post\u001b[39m\u001b[34m(self, request_parameters, stream)\u001b[39m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.iter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response.content\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:480\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: 402 Client Error: Payment Required for url: https://router.huggingface.co/novita/v3/openai/chat/completions (Request ID: Root=1-68f6677c-40a610cf1707f9d25fe750f5;f19f4136-70cb-4880-9b78-c0b394d3f9c2)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits."
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Create templatized prompt\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Pass context and question into prompt, then pass prompt to LLM\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chat_model\n",
    "    | StrOutputParser()\n",
    "    | RunnableLambda(parse_and_clean_output)\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83549b1",
   "metadata": {},
   "source": [
    "### **RAG Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith.schemas import Run, Example\n",
    "from langsmith.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d25be",
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithError",
     "evalue": "Failed to POST /datasets in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Forbidden\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langsmith\\utils.py:159\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://api.smith.langchain.com/datasets",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langsmith\\client.py:950\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    944\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    945\u001b[39m         method,\n\u001b[32m    946\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    947\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    948\u001b[39m         **request_kwargs,\n\u001b[32m    949\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langsmith\\utils.py:161\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 403 Client Error: Forbidden for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Forbidden\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     24\u001b[39m dataset_outputs = [\n\u001b[32m     25\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mClimate normals are 30-year averages of meteorological conditions, such as air temperature and precipitation. They characterize the background state of the climate.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     26\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mThe new set of NOAA\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms climate normals is the 1981-2010 set, which replaces the 1971-2000 normals.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mQuasi normals are estimated normals for active short-record stations (at least 2 years of complete months) that fail the 10-year completeness criterion. They are estimated using linear combinations of normals from neighboring longer-record stations.\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     39\u001b[39m ]\n\u001b[32m     42\u001b[39m client = Client()\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m dataset = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNOAA Climate Normals Questions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNOAA Climate Normals questions for RAG pipeline evaluation.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m client.create_examples(\n\u001b[32m     50\u001b[39m     inputs=[{\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: q} \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m dataset_inputs],\n\u001b[32m     51\u001b[39m     outputs=dataset_outputs,\n\u001b[32m     52\u001b[39m     dataset_id=dataset.id,\n\u001b[32m     53\u001b[39m )\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccessfully created dataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset_inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m examples.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langsmith\\client.py:3828\u001b[39m, in \u001b[36mClient.create_dataset\u001b[39m\u001b[34m(self, dataset_name, description, data_type, inputs_schema, outputs_schema, transformations, metadata)\u001b[39m\n\u001b[32m   3825\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3826\u001b[39m     dataset[\u001b[33m\"\u001b[39m\u001b[33moutputs_schema_definition\u001b[39m\u001b[33m\"\u001b[39m] = outputs_schema\n\u001b[32m-> \u001b[39m\u001b[32m3828\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3829\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3830\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/datasets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_orjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3833\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3834\u001b[39m ls_utils.raise_for_status_with_text(response)\n\u001b[32m   3836\u001b[39m json_response = response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Work\\Python\\RAGs\\myRAG\\Lib\\site-packages\\langsmith\\client.py:1010\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m   1008\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[32m   1009\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithError(\n\u001b[32m   1011\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1012\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1013\u001b[39m     )\n\u001b[32m   1014\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1015\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithError(\n\u001b[32m   1016\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1017\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m     )\n",
      "\u001b[31mLangSmithError\u001b[39m: Failed to POST /datasets in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Forbidden\"}')"
     ]
    }
   ],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "\n",
    "dataset_inputs = [\n",
    "    \"What are Climate Normals?\",\n",
    "    \"What is the new set of NOAA's climate normals?\",\n",
    "    \"What are the overarching goals of NOAA's 1981-2010 U.S. Climate Normals?\",\n",
    "    \"What are the three major product lines in the new normals?\",\n",
    "    \"What is the history of NOAA's climate normals?\",\n",
    "    \"When did NOAA's NCDC become the official archive for weather records?\",\n",
    "    \"Who is NCDC's official source for calculations of U.S. normals?\",\n",
    "    \"When are climatological standard normals computed?\",\n",
    "    \"What are the products included in the 1981-2010 Climate Normals?\",\n",
    "    \"What are the temperature-related normals?\",\n",
    "    \"What are precipitation-related climate normals?\",\n",
    "    \"What is the methodological overview for the 1981-2010 climate normals?\",\n",
    "    \"How are higher-quality monthly data achieved in the 1981-2010 normals?\",\n",
    "    \"What are quasi normals for short-record stations?\"\n",
    "]\n",
    "\n",
    "dataset_outputs = [\n",
    "    {\"answer\": \"Climate normals are 30-year averages of meteorological conditions, such as air temperature and precipitation. They characterize the background state of the climate.\"},\n",
    "    {\"answer\": \"The new set of NOAA's climate normals is the 1981-2010 set, which replaces the 1971-2000 normals.\"},\n",
    "    {\"answer\": \"The goals include producing high-quality normals for many U.S. stations, being representative of the 1981-2010 period, reflecting station locations and observing practices at the end of 2010, adding new products, developing new statistical techniques, and providing timely access.\"},\n",
    "    {\"answer\": \"The three major product lines are temperature-related, precipitation-related, and hourly normals.\"},\n",
    "    {\"answer\": \"NOAA's NCDC is responsible for recording U.S. climatic conditions, stemming from the Organic Act of 1890. The WMO set guidelines for 30-year periods, and NOAA has been computing decennial 30-year normals since the 1921-50 period.\"},\n",
    "    {\"answer\": \"The Federal Records Act of 1950 established NOAA's NCDC as the official archive for weather records.\"},\n",
    "    {\"answer\": \"NOAA's National Climatic Data Center (NCDC) is the official source for calculations of U.S. normals.\"},\n",
    "    {\"answer\": \"Climatological standard normals are computed every 30 years as part of an international effort led by the WMO. Standard normals for 1901-30, 1931-60, and 1961-90 have been distributed.\"},\n",
    "    {\"answer\": \"Products include station-based temperature, precipitation, snowfall, and snow depth normals at daily, monthly, seasonal, and annual scales, as well as degree days and threshold exceedance frequencies.\"},\n",
    "    {\"answer\": \"Temperature-related normals are based on daily observations of maximum temperature (Tmax) and minimum temperature (Tmin). They include normals for Tmax, Tmin, mean temperature (Tavg), diurnal temperature range (DTR), heating degree days (HDDs), cooling degree days (CDDs), and threshold exceedance frequencies.\"},\n",
    "    {\"answer\": \"Precipitation-related normals (precipitation, snowfall, snow depth) are based on daily observations. They include monthly, seasonal, and annual averages, month-to-date and year-to-date normals, threshold exceedance frequencies, and percentiles.\"},\n",
    "    {\"answer\": \"The values come from the Global Historical Climatology Network-Daily (GHCN-Daily) dataset, which undergoes extensive quality assurance. Data flagged as erroneous are treated as missing. A station needs at least 10 'sufficiently complete' months for each month of the year.\"},\n",
    "    {\"answer\": \"The 1981-2010 normals use monthly temperature data (Tmax and Tmin) that undergo robust QA and homogenization using a pairwise comparison technique, which is then passed down to the daily time scale.\"},\n",
    "    {\"answer\": \"Quasi normals are estimated normals for active short-record stations (at least 2 years of complete months) that fail the 10-year completeness criterion. They are estimated using linear combinations of normals from neighboring longer-record stations.\"}\n",
    "]\n",
    "\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=\"NOAA Climate Normals Questions\",\n",
    "    description=\"NOAA Climate Normals questions for RAG pipeline evaluation.\",\n",
    ")\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in dataset_inputs],\n",
    "    outputs=dataset_outputs,\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n",
    "print(f\"Successfully created dataset '{dataset.name}' with {len(dataset_inputs)} examples.\")\n",
    "print(f\"View it in LangSmith: {dataset.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Define Custom Evaluator ---\n",
    "def must_mention(run: Run, example: Example) -> dict:\n",
    "    \"\"\"\n",
    "    Checks if the model's output contains any of the required phrases.\n",
    "    \"\"\"\n",
    "    # Get the RAG chain's output\n",
    "    prediction = run.outputs.get(\"output\") or \"\"\n",
    "    \n",
    "    # Get the \"ground truth\" required phrases from the dataset\n",
    "    required = example.outputs.get(\"must_mention\") or []\n",
    "    \n",
    "    # Score is 1 (True) if ANY required phrase is in the prediction, 0 (False) otherwise\n",
    "    score = any(phrase.lower() in prediction.lower() for phrase in required)\n",
    "    \n",
    "    return {\"key\": \"must_mention\", \"score\": int(score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = final_rag_chain \n",
    "dataset_name = \"NOAA Climate Normals Questions\"\n",
    "\n",
    "def query_wrapper(query_dict: dict) -> dict:\n",
    "    response = runner.invoke(query_dict) \n",
    "    return {\"output\": response}\n",
    "\n",
    "\n",
    "evaluators = [must_mention]\n",
    "\n",
    "print(f\"Starting evaluation on dataset: {dataset_name}...\")\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    query_wrapper,         # The function to test (your RAG chain)\n",
    "    data=dataset_name,     # The dataset to test against\n",
    "    evaluators=evaluators, # The list of grading functions\n",
    "    experiment_prefix=\"noaa-rag-pipeline\", # A name for the test run\n",
    "    client=client,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Evaluation Complete ---\")\n",
    "print(experiment_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
